from libs import * 

sys.path.insert(1, '/homecentral/alexandre.mahrach/gdrive/postdoc_IDIBAPS/python/data_analysis') 

import data.constants as gv 
importlib.reload(gv) ; 

import data.utils as data 
importlib.reload(data) ; 

import data.fct_facilities as fac
importlib.reload(fac) ; 
fac.SetPlotParams() 

import preprocessing as prep
from plotting import *

pal = ['r','b','y']

trial_type = ['ND'] * 32 + ['D1'] * 32 + ['D2'] * 32
n_components=3

for gv.mouse in [gv.mice[2]] : 

    data.get_sessions_mouse() 
    data.get_stimuli_times() 
    data.get_delays_times()
    
    for gv.session in [gv.sessions[-1]] : 
        X, y = data.get_fluo_data()
        print('mouse', gv.mouse, 'session', gv.session, 'data X', X.shape,'y', y.shape) 
        
        data.get_delays_times() 
        data.get_frame_rate() 
        data.get_bins(t_start=0) 

        F0 = np.mean(X[:,:,gv.bins_baseline],axis=2)
        F0 = F0[:,:, np.newaxis]
        
        X = (X -F0) / (F0 + 0.0000001) 
        
        gv.duration = X.shape[2]/gv.frame_rate 
        time = np.linspace(0, gv.duration, X.shape[2]) ; 

        n_trials = X.shape[0] 
        n_neurons = X.shape[1] 
        trial_size = X.shape[2] 

        trials = []
        for gv.trial in gv.trials:
            X_S1, X_S2 = data.get_S1_S2_trials(X, y) 
            data.get_trial_types(X_S1)

            print('X_S1', X_S1.shape, 'X_S2', X_S2.shape)

            X_S1_S2 = np.vstack((X_S1, X_S2))
            X_S1_S2 = np.reshape((X_S1_S2), (X_S1_S2.shape[1], X_S1_S2.shape[0]* X_S1_S2.shape[2]))

            print('X_S1_S2', X_S1_S2.shape)

            trials.append(X_S1_S2)
        
        Xl = np.hstack(trials) 
        Xl = prep.z_score(Xl)
        
        print('Xl', Xl.shape)
        
        pca = PCA(n_components=n_components)
        Xl_p = pca.fit_transform(Xl.T).T
        print('explained_variance', pca.explained_variance_ratio_)
        
        gt = {comp : {t_type : [] for t_type in gv.trials} for comp in range(n_components)}

        for comp in range(n_components):
            for i, t_type in enumerate(trial_type):
                t = Xl_p[comp, trial_size * i: trial_size * (i + 1)]
                gt[comp][t_type].append(t)

        X_proj = []
        for comp in range(n_components):
            for t_type in gv.trials: 
                gt[comp][t_type] = np.vstack(gt[comp][t_type]).transpose() 
                gt[comp][t_type] = gt[comp][t_type].reshape(gv.trial_size, len(gv.samples), int(gv.n_trials/len(gv.samples))) 
                X_proj.append(gt[comp][t_type])

        X_proj=np.asarray(X_proj).reshape( len(gv.trials), n_components, gv.trial_size, len(gv.samples), int(gv.n_trials/len(gv.samples)))
        X_proj = np.moveaxis(X_proj, 0,4) 
        X_proj = np.moveaxis(X_proj, 1,4) 
        print(X_proj.shape)
        
        f, axes = plt.subplots(1, 3, figsize=[10, 2.8], sharey=True, sharex=True)
        x = time
        for comp in range(3):
            ax = axes[comp]
            for t, t_type in enumerate(gv.trials):
                for i  in range(2):
                    y = np.mean(gt[comp][t_type][:,i,:],axis=1) 
                    ax.plot(x, y, color=pal[t]) 
                    ci = stats.t.interval(0.95, len(y)-1, loc=np.mean(y), scale=stats.sem(y)) 
                    ax.fill_between(x, y-ci[0], y+ci[1] , color=pal[t], alpha=.1) 
                add_stim_to_plot(ax) 
                ax.set_xlim([0, gv.t_test[1]+1])
            ax.set_ylabel('PC {}'.format(comp+1))
            axes[1].set_xlabel('Time (s)')
            sns.despine(right=True, top=True)
            add_orientation_legend(axes[2])
